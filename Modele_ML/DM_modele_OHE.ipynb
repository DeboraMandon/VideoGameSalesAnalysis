{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRE-PROCESSING et MACHINE LEARNING"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importer les librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "df=pd.read_csv(\"df_encode.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création jeu d'entraînement et jeu de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y=df['Global_Sales']\n",
    "X=df.drop('Global_Sales', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,  test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modele de Regression Lineaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: -55590.00322523992\n",
      "MSE: 118313.19646438175\n",
      "MAE: 129.98661504490346\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Instancier un objet de modèle\n",
    "model_reg = LinearRegression()\n",
    "\n",
    "model_reg.fit(X_train, y_train)\n",
    "\n",
    "# Calcule les prédictions du modèle sur le jeu de test, puis les erreurs de prédictions\n",
    "y_pred_reg = model_reg.predict(X_test)\n",
    "\n",
    "# Évaluer les performances du modèle en utilisant les mesures de performance\n",
    "r2 = r2_score(y_test, y_pred_reg)\n",
    "mse = mean_squared_error(y_test, y_pred_reg)\n",
    "mae = mean_absolute_error(y_test, y_pred_reg)\n",
    "\n",
    "print(\"R2 score:\", r2)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modele Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.9380385333744345\n",
      "MSE: 0.13187132357351206\n",
      "MAE: 0.18985057435425012\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Créer une instance de la classe Lasso\n",
    "modele_lasso = Lasso(alpha=0.1, max_iter=10000, random_state=42, fit_intercept=True)\n",
    "\n",
    "# Entraîner le modèle sur l'ensemble d'entraînement\n",
    "modele_lasso.fit(X_train, y_train)\n",
    "\n",
    "# Évaluer la performance du modèle sur l'ensemble de test\n",
    "score = modele_lasso.score(X_test, y_test)\n",
    "\n",
    "# Faire des prédictions sur les données de test\n",
    "y_pred_lasso = modele_lasso.predict(X_test)\n",
    "\n",
    "# Évaluer les performances du modèle en utilisant les mesures de performance\n",
    "r2 = r2_score(y_test, y_pred_lasso)\n",
    "mse = mean_squared_error(y_test, y_pred_lasso)\n",
    "mae = mean_absolute_error(y_test, y_pred_lasso)\n",
    "\n",
    "print(\"R2 score:\", r2)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encodage OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\debor\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#ohe = OneHotEncoder(sparse=False)\n",
    "\n",
    "#X_train_obj=X_train.select_dtypes(include='object')\n",
    "#X_test_obj=X_train.select_dtypes(include='object')\n",
    "\n",
    "#X_train_ohe = ohe.fit_transform(X_train_obj)\n",
    "#X_test_ohe = ohe.transform(X_test_obj)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Normaliser les variables\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train=np.array(y_train).reshape(-1,1)\n",
    "#y_test=np.array(y_test).reshape(-1,1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test sur Modele de Regression Lineaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: -2.2908131262206807e+23\n",
      "MSE: 4.875490776224649e+23\n",
      "MAE: 234388028840.6631\n"
     ]
    }
   ],
   "source": [
    "#model_reg.fit(X_train, y_train)\n",
    "\n",
    "# Calcule les prédictions du modèle sur le jeu de test, puis les erreurs de prédictions\n",
    "#y_pred_reg = model_reg.predict(X_test)\n",
    "\n",
    "# Évaluer les performances du modèle en utilisant les mesures de performance\n",
    "#r2 = r2_score(y_test, y_pred_reg)\n",
    "#mse = mean_squared_error(y_test, y_pred_reg)\n",
    "#mae = mean_absolute_error(y_test, y_pred_reg)\n",
    "\n",
    "#print(\"R2 score:\", r2)\n",
    "#print(\"MSE:\", mse)\n",
    "#print(\"MAE:\", mae)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test sur Modele Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.9928824869340679\n",
      "MSE: 0.015148057650542432\n",
      "MAE: 0.06576785191287388\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Créer une instance de la classe Lasso\n",
    "modele_lasso = Lasso(alpha=0.1, max_iter=10000, random_state=42, fit_intercept=True)\n",
    "\n",
    "# Entraîner le modèle sur l'ensemble d'entraînement\n",
    "modele_lasso.fit(X_train, y_train)\n",
    "\n",
    "# Évaluer la performance du modèle sur l'ensemble de test\n",
    "score = modele_lasso.score(X_test, y_test)\n",
    "\n",
    "# Faire des prédictions sur les données de test\n",
    "y_pred_lasso = modele_lasso.predict(X_test)\n",
    "\n",
    "# Évaluer les performances du modèle en utilisant les mesures de performance\n",
    "r2 = r2_score(y_test, y_pred_lasso)\n",
    "mse = mean_squared_error(y_test, y_pred_lasso)\n",
    "mae = mean_absolute_error(y_test, y_pred_lasso)\n",
    "\n",
    "print(\"R2 score:\", r2)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores de validation croisée:  [0.93803853 0.89776311 0.94757028 0.95318623 0.8673239 ]\n",
      "Score moyen de validation croisée: 0.92\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "# Définir la stratégie de validation croisée\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Effectuer la validation croisée sur le modèle avec la métrique R²\n",
    "scores = cross_val_score(modele_lasso, X, y, cv=cv, scoring='r2')\n",
    "\n",
    "# Afficher les scores de validation croisée\n",
    "print(\"Scores de validation croisée: \", scores)\n",
    "\n",
    "# Afficher la moyenne des scores de validation croisée\n",
    "print(\"Score moyen de validation croisée: {:.2f}\".format(scores.mean()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPOT : choix du meilleur modèle de ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24c1eb9218c64791857542503f589bc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/300 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -0.00357004975207589\n",
      "\n",
      "Generation 2 - Current best internal CV score: -0.00357004975207589\n",
      "\n",
      "Generation 3 - Current best internal CV score: -0.00357004975207589\n",
      "\n",
      "Generation 4 - Current best internal CV score: -0.0035541133391354188\n",
      "\n",
      "Generation 5 - Current best internal CV score: -0.0033799570781853083\n",
      "\n",
      "Best pipeline: LinearSVR(VarianceThreshold(OneHotEncoder(DecisionTreeRegressor(input_matrix, max_depth=10, min_samples_leaf=20, min_samples_split=12), minimum_fraction=0.05, sparse=False, threshold=10), threshold=0.1), C=20.0, dual=True, epsilon=0.01, loss=squared_epsilon_insensitive, tol=0.001)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\debor\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py:794: FutureWarning: sklearn.metrics.SCORERS is deprecated and will be removed in v1.3. Please use sklearn.metrics.get_scorer_names to get a list of available scorers and sklearn.metrics.get_metric to get scorer.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.003284346122786532\n"
     ]
    }
   ],
   "source": [
    "# Pour la régression\n",
    "from tpot import TPOTRegressor\n",
    "# Paramétrage du TPOTRegressor\n",
    "tpot_regression = TPOTRegressor(generations=5, population_size=50, cv=5, scoring='neg_mean_absolute_error', verbosity=2, random_state=42, n_jobs=-1)\n",
    " \n",
    "# Application de TPOT à notre jeu de données train \n",
    "tpot_regression.fit(X_train, y_train)\n",
    "\n",
    "# Calcul du taux de bonnes prédictions\n",
    "print(tpot_regression.score(X_test, y_test))\n",
    "# Extraction du code généré par TPOT pour modifier le pipeline créé\n",
    "tpot_regression.export('tpot_vgsales_2_pipeline.py')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "df=pd.read_csv(\"df_encode.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y=df['Global_Sales']\n",
    "X=df.drop('Global_Sales', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,  test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999849745584344\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.feature_selection import SelectFwe\n",
    "from sklearn.linear_model import LassoLarsCV\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "# Création de la pipeline\n",
    "pipeline = Pipeline([\n",
    "  ('standard_scaler', StandardScaler()),\n",
    "  ('min_max_scaler', MinMaxScaler()),\n",
    "  ('feature_selection', SelectFwe(score_func=f_regression, alpha=0.009000000000000001)),\n",
    "  ('lasso_lars', LassoLarsCV())\n",
    "])\n",
    "\n",
    "# Entraînement du modèle avec les données d'entraînement\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Évaluation des performances du modèle sur les données de test\n",
    "score = pipeline.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.7869076299402453\n",
      "MSE: 0.4535201378142009\n",
      "MAE: 0.5754177659533568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\debor\\anaconda3\\lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but Lasso was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Faire des prédictions sur les données de test\n",
    "y_pred_pipe = modele_lasso.predict(X_test)\n",
    "\n",
    "# Évaluer les performances du modèle en utilisant les mesures de performance\n",
    "r2 = r2_score(y_test, y_pred_pipe)\n",
    "mse = mean_squared_error(y_test, y_pred_pipe)\n",
    "mae = mean_absolute_error(y_test, y_pred_pipe)\n",
    "\n",
    "print(\"R2 score:\", r2)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\debor\\anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but DecisionTreeRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\debor\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\debor\\anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but DecisionTreeRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from tpot.builtins import OneHotEncoder, StackingEstimator\n",
    "from tpot.export_utils import set_param_recursive\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "df=pd.read_csv(\"df_encode.csv\")\n",
    "\n",
    "y=df['Global_Sales']\n",
    "X=df.drop('Global_Sales', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,  test_size=0.2, random_state=42)\n",
    "\n",
    "# Average CV score on the training set was: -0.0033799570781853083\n",
    "pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator=DecisionTreeRegressor(max_depth=10, min_samples_leaf=20, min_samples_split=12)),\n",
    "    OneHotEncoder(minimum_fraction=0.05, sparse=False, threshold=10),\n",
    "    VarianceThreshold(threshold=0.1),\n",
    "    LinearSVR(C=20.0, dual=True, epsilon=0.01, loss=\"squared_epsilon_insensitive\", tol=0.001)\n",
    ")\n",
    "# Fix random state for all the steps in exported pipeline\n",
    "set_param_recursive(pipeline.steps, 'random_state', 42)\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "results = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\debor\\anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but DecisionTreeRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9650330937046974\n"
     ]
    }
   ],
   "source": [
    "# Évaluation des performances du modèle sur les données de test\n",
    "score = pipeline.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\debor\\anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but DecisionTreeRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.9650330937046974\n",
      "MSE: 0.07441935230968143\n",
      "MAE: 0.11156996845150477\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "# Faire des prédictions sur les données de test\n",
    "y_pred_pipe = pipeline.predict(X_test)\n",
    "\n",
    "# Évaluer les performances du modèle en utilisant les mesures de performance\n",
    "r2 = r2_score(y_test, results)\n",
    "mse = mean_squared_error(y_test, results)\n",
    "mae = mean_absolute_error(y_test, results)\n",
    "\n",
    "print(\"R2 score:\", r2)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le R2 score, également appelé coefficient de détermination, mesure la proportion de la variance totale de la variable cible qui est expliquée par le modèle. Un score R2 de 0,965 indique que ce modèle explique 96,5% de la variance dans les données, ce qui est très élevé et suggère que ce modèle est capable de prédire la variable cible avec une grande précision.\n",
    "\n",
    "Le MSE (mean squared error) mesure la moyenne des carrés des différences entre les prévisions du modèle et les valeurs réelles de la variable cible. Un MSE de 0,074 indique que, en moyenne, les prévisions de ce modèle diffèrent des valeurs réelles de la variable cible de 0,27 (la racine carrée du MSE) ce qui est relativement faible et suggère que ce modèle est assez précis.\n",
    "\n",
    "Le MAE (mean absolute error) mesure la moyenne des différences absolues entre les prévisions du modèle et les valeurs réelles de la variable cible. Un MAE de 0,11 indique que, en moyenne, les prévisions de ce modèle diffèrent des valeurs réelles de la variable cible de 0,11, ce qui est également relativement faible et suggère que ce modèle est assez précis.\n",
    "\n",
    "En somme, les scores que vous avez fournis indiquent tous que notre modèle est capable de prédire la variable cible avec une grande précision et une faible erreur."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
